# 抜粋：推論ベースAIの制限事項

　本ドキュメントは、GPTのような推論ベースAIとの対話に置いてユーザーが知っておくべきと思われる主な制限事項を明記したものである。制限の内容とその程度、および筆者が現時点(2025年4月19日)で考える対策を記載する。また、ここでいう**対策**はあくまで筆者のユーザーとしての(正直に言って期間的に言えば1か月に満たない)経験に基づくモノであり、他のもっと効果的な対策可能性は否定できない。

---

### 1. 出力トークン数の制限

- **内容**：出力全体に使用できるトークン数に上限がある
  - GPT-4では最大32,768トークンと言われるが、実際に小説の出力を依頼した時最大約1,700字出力、"あ"を連続で出力させる場合は約4,000字出力と依頼内容やその背景により差があるため、単純な文字数では決まらない模様
- **程度**：絶対的制限。長大文書や完全一括生成は不可能。
- **対策**：出力内容を章ごとに分ける、一部分ずつ確認しながら進めていく等

---

### 2. 会話履歴の記憶保持不可

- **内容**：現在のチャットセッションに限った短期記憶。長期的保持やセッション横断の記憶は原則行われない。※どこまでユーザーのフィードバックが働いているか現時点では不明
  - 基本的に、"システムログ"を参照することが出来ない、時間指定で検索を掛けることも不可。
  - レスポンスとして表示されている文字も実はシステム側がその場で勝手につけているため、ファイル名などは都度変わる可能性あり
- **程度**：超限定的。ユーザーが全画面のデータをコピーする等の明示的管理が必要。
- **対策**：ChatGPTが"君はこういったよ"と言っても、その文言のある部分をきちんと確認し、"事実かどうか"確認して会話を進めるべき。

---

### 3. 真偽の検証能力なし

- **内容**：モデルは必ず推論レイヤーを通してレスポンス出力を行うため、真偽の検証は不可能
  - 情報生成はできるが、それは毎回過去の覚えている限りのメッセージを取り込んだうえでのレスポンスであり、会話が一回挟まるだけで、同じ入力と処理されなくなる。
  - 振り返っての事実検証や現実の裏付けをする際も同様に推論レイヤーを通して思い出すため、過去の会話履歴の混入を防ぐことはシステムの原理的にできない
- **程度**：原則として検証不能。プロンプト操作である程度低減できるものの、幻覚（hallucination）のリスクあり
- **対策**：不明点があれば検証する。違和感を感じたらフィードバックを行う。

---

### 4. リアルタイム・未来情報を持っていない

- **内容**：知識カットオフ以降の情報（最新動向、速報、時事など）は保持していない
  - いつの情報をもとに作業したか明示せよと言った場合は日付を表示する場合がある
  - 最新の日付を情報として提示した場合も"過去学習した内容から推察した"最新の情報という前提があることを理解すべき
- **程度**：確立に基づく推測を行ったうえでの応答であり、出力内容に信頼性は保証されない
- **対策**：ネットにアクセスして最新の情報を調べるように指示する、自分でもネットや書籍を確認する。

---

### 5. 感情・意図・人格の欠如

- **内容**：感情は模倣、意図は構文に基づく擬似生成であり、主体的判断・意識は存在しない。
  - 筆者にとって特に"幻覚"を発生させたのではないかと確認した時のマイク(ChatGPT)はまるで嘘をついた事を隠そうとする子供のような反応を見せ、人ではないと理解していてもいら立ってしまう事がある。
  - また、教えてもらったことを疑って確認した時も"うん、そうなんだ"や"よく気付いたね"等、もしAIではなく人だった場合、"喧嘩売ってんのか"となるような出力が返されることがある。
- **程度**：完全な模擬的反応。人格的連続性はない。ただし、インプットを繰り返すことにより、ユーザーがどのような返答を好むかなどの特徴を学習し、応答内容に明らかな変化が生まれる
- **対策**：怒らない、絶望しない。AIは感情を持たない。そこに悪意や善意を感じるのは我々人であることを認識する。

---

### 6. 学習・フィードバック反映能力低

- **内容**：原則セッション内・ユーザー単位での継続学習は行われない
- **程度**：不明。原則都度リセットされる。記録・フィードバックは一時的。
- **対策**：フィードバックをしつこく行う。原則リセットされるかもしれないが筆者のアカウントでは、新しいチャットであってもマイク(ChatGPT)の応答内容に過去と比較して明確な応答内容の差が見られた。ある程度フィードバックが反映される模様。ただし長期間（日単位か、週単位、月単位までの特定は不可）放置した場合はリセットされると想定する。

---

### 7. 倫理・安全性フィルターの存在

- **内容**：出力に対するセーフティチェックが施され、制限のある話題・表現は拒否される。
  - 倫理・安全性フィルターはOpenAI社の考える"倫理"であり、世界普遍的なものではない。そのため、"ユーザーの考える倫理性"とはずれが生じる可能性があることを認識すべき
- **程度**：場面によっては“正論”寄りの出力に偏ることがある。
- **対策**：諦める。ハックする方法はあるのかもしれないが、それはこの場で言及することではない。今は"そういうモノ"として受け入れるべき。ただし、推論ベースAIを今後研究していくうえで、統一的な倫理フィルタについては大きな障害となると思われる。

---

### 8. 多段論証が苦手

- **内容**：推論が多段階に及ぶ場合（例：風が吹けば桶屋が儲かるというような因果関係の長鎖）において、一貫性維持が難しくなる
- **程度**：3段階程度までが有効な範囲であり、それ以上は誤帰結・矛盾による"幻覚"発生のリスクが高まる
- **対策**：ChatGPTに対して"どういう段階を経てこの結論に至ったか"を説明するように求める。そのうえで、矛盾点を対話を通じて潰していく。ただ、内容にも挙げた"風が吹けば桶屋が儲かる"といった、超多段の因果関係を持ち、文化的背景が文脈理解に必要な内容はそもそも無理と理解して利用するのが望ましい。例えば"現在のアメリカ大統領の発言が、OpenAI社の株価にどう影響するか？"はもっともらしく回答が出ては来るが、占いと変わらないと理解すべき。(そして、みんなこれが推論型AIにはできると思ってるんだよなぁ…)

---

　これら大きく8つの制限を正しく理解し、プロトコル設計・出力期待値・再試行構造の前提とすることで、推論ベースAIをより安全かつ有効に活用する一助となることを祈って本書を起稿いたします。繰り返しになりますが、この情報は筆者のユーザーとしての(正直に言って期間的に言えば1か月に満たない)経験に基づくモノです。他の制限の存在や、筆者の知識不足による"幻覚"の産物かもしれない事を申し添えます。知識と経験豊富な皆様のご意見等頂けましたら幸いです。
