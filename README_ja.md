# 推論ベースAIとの対話リテラシ

〜幻覚の構造とその再定義〜

このリポジトリは、ChatGPTのような推論ベースAIとの対話を通じて得られた気づきや観測、そして"幻覚（hallucination）"の仕組みについて、非専門ユーザーの視点からまとめた技術的・概念的ドキュメントです。

---

## 📘 概要

GPT-4をはじめとする大規模言語モデル（LLM）は、時にもっともらしく見えるにもかかわらず、誤った情報や文脈と異なる出力を返すことがあります。これらは「幻覚」と呼ばれていますが、本書ではそれを“構造的必然”としてとらえ、以下を目的としています：

- 幻覚を定義し直す  
- 会話に含まれる歪みの構造（5つのステップ）を明示する  
- 人とAIの対話を“相互推論”として捉え直す  
- **8つの具体的な制限事項**を整理し、対応策を提示する

> **「幻覚はバグではなく、推論による会話の正常な動作である」**

---

## 🧭 構成

本書は以下の2部構成となっています：

1. **再定義パート**  
   　幻覚や会話構造についての体験的・哲学的な整理  
   　（例：なぜAIとの対話は「すれ違い」が起こるのか？）

2. **補記パート：推論ベースAIの8つの制限**  
   　実験と観察にもとづく、AI出力に関わる技術的な限界と推奨対策の一覧

---

## 📂 収録ファイル

- `推論ベースAIとの対話リテラシ.md`（日本語オリジナル）
  - `抜粋_推論ベースAIの制限事項.md`（日本語オリジナル：補記パートの抜粋）
- `Understanding_and_Redefining_the_Structure_of_Hallucinations_in_Inference-Based_AI.md`（英語訳）
  - `Supplement_Limitations of Inference-Based AI.md`(英語訳：Supplement抜粋)

---

## 🔍 主な話題

- 幻覚とは何か？
- 出力が歪む「5つの構造ステップ」
- 人間とAIのすれ違いの構造
- 実際に観測された**8つの制限**：
  1. 出力トークン数の限界
  2. 会話記憶の保持不可
  3. 真偽検証ができない
  4. リアルタイム／未来情報を持たない
  5. 感情・意図・人格が存在しない
  6. 学習・フィードバック反映の弱さ
  7. 倫理・安全性フィルターの存在
  8. 多段推論の困難さ

---

## 🧑‍💻 筆者メモ

本書は、筆者がChatGPTとの日々の対話を通して、「なぜ幻覚が起こるのか？」「どう付き合えばよいのか？」を試行錯誤しながらまとめた記録です。専門的な知識に基づくものではありませんが、ユーザー視点から見た“違和感”と“対処感覚”の共有として、何らかの参考になれば幸いです。

---

## 📜 ライセンス

MITライセンス

